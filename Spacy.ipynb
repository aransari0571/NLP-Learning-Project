{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c6f5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f886416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c9fdc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.7\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5c0a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "#Load the small English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "#Sample text\n",
    "text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
    "doc = nlp(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dac25f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple is looking at buying U.K. startup for $1 billion"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05e432c",
   "metadata": {},
   "source": [
    "# TEXT Summarization --Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5342d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc1 = nlp(\"Data Science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to \" \\\n",
    "\"extract knowledge and insights from structured and unstructured data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddbf1794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data Science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f4e77e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "Science\n",
      "is\n",
      "an\n",
      "interdisciplinary\n",
      "field\n",
      "that\n",
      "uses\n",
      "scientific\n",
      "methods\n",
      ",\n",
      "processes\n",
      ",\n",
      "algorithms\n",
      "and\n",
      "systems\n",
      "to\n",
      "extract\n",
      "knowledge\n",
      "and\n",
      "insights\n",
      "from\n",
      "structured\n",
      "and\n",
      "unstructured\n",
      "data\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data Science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROPN\n",
      "PROPN\n",
      "AUX\n",
      "DET\n",
      "ADJ\n",
      "NOUN\n",
      "PRON\n",
      "VERB\n",
      "ADJ\n",
      "NOUN\n",
      "PUNCT\n",
      "NOUN\n",
      "PUNCT\n",
      "NOUN\n",
      "CCONJ\n",
      "NOUN\n",
      "PART\n",
      "VERB\n",
      "NOUN\n",
      "CCONJ\n",
      "NOUN\n",
      "ADP\n",
      "ADJ\n",
      "CCONJ\n",
      "ADJ\n",
      "NOUN\n",
      "PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data : PROPN\n",
      "Science : PROPN\n",
      "is : AUX\n",
      "an : DET\n",
      "interdisciplinary : ADJ\n",
      "field : NOUN\n",
      "that : PRON\n",
      "uses : VERB\n",
      "scientific : ADJ\n",
      "methods : NOUN\n",
      ", : PUNCT\n",
      "processes : NOUN\n",
      ", : PUNCT\n",
      "algorithms : NOUN\n",
      "and : CCONJ\n",
      "systems : NOUN\n",
      "to : PART\n",
      "extract : VERB\n",
      "knowledge : NOUN\n",
      "and : CCONJ\n",
      "insights : NOUN\n",
      "from : ADP\n",
      "structured : ADJ\n",
      "and : CCONJ\n",
      "unstructured : ADJ\n",
      "data : NOUN\n",
      ". : PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token.text, ':', token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data : PROPN --> Data compound\n",
      "Science : PROPN --> Science nsubj\n",
      "is : AUX --> be ROOT\n",
      "an : DET --> an det\n",
      "interdisciplinary : ADJ --> interdisciplinary amod\n",
      "field : NOUN --> field attr\n",
      "that : PRON --> that nsubj\n",
      "uses : VERB --> use relcl\n",
      "scientific : ADJ --> scientific amod\n",
      "methods : NOUN --> method dobj\n",
      ", : PUNCT --> , punct\n",
      "processes : NOUN --> process conj\n",
      ", : PUNCT --> , punct\n",
      "algorithms : NOUN --> algorithm conj\n",
      "and : CCONJ --> and cc\n",
      "systems : NOUN --> system conj\n",
      "to : PART --> to aux\n",
      "extract : VERB --> extract xcomp\n",
      "knowledge : NOUN --> knowledge dobj\n",
      "and : CCONJ --> and cc\n",
      "insights : NOUN --> insight conj\n",
      "from : ADP --> from prep\n",
      "structured : ADJ --> structured amod\n",
      "and : CCONJ --> and cc\n",
      "unstructured : ADJ --> unstructured conj\n",
      "data : NOUN --> datum pobj\n",
      ". : PUNCT --> . punct\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token.text, ':', token.pos_, '-->',token.lemma_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data Science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from structured and unstructured data."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Data PROPN NNP compound Xxxx True False\n",
      "Science Science PROPN NNP nsubj Xxxxx True False\n",
      "is be AUX VBZ ROOT xx True True\n",
      "an an DET DT det xx True True\n",
      "interdisciplinary interdisciplinary ADJ JJ amod xxxx True False\n",
      "field field NOUN NN attr xxxx True False\n",
      "that that PRON WDT nsubj xxxx True True\n",
      "uses use VERB VBZ relcl xxxx True False\n",
      "scientific scientific ADJ JJ amod xxxx True False\n",
      "methods method NOUN NNS dobj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "processes process NOUN NNS conj xxxx True False\n",
      ", , PUNCT , punct , False False\n",
      "algorithms algorithm NOUN NNS conj xxxx True False\n",
      "and and CCONJ CC cc xxx True True\n",
      "systems system NOUN NNS conj xxxx True False\n",
      "to to PART TO aux xx True True\n",
      "extract extract VERB VB xcomp xxxx True False\n",
      "knowledge knowledge NOUN NN dobj xxxx True False\n",
      "and and CCONJ CC cc xxx True True\n",
      "insights insight NOUN NNS conj xxxx True False\n",
      "from from ADP IN prep xxxx True True\n",
      "structured structured ADJ JJ amod xxxx True False\n",
      "and and CCONJ CC cc xxx True True\n",
      "unstructured unstructured ADJ JJ conj xxxx True False\n",
      "data datum NOUN NNS pobj xxxx True False\n",
      ". . PUNCT . punct . False False\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token.text, token.lemma_, token.pos_,token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23cd55f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Apple is looking at buying U.K. startup for $1 billion"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54287dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Apple PROPN NNP nsubj Xxxxx True False\n",
      "is be AUX VBZ aux xx True True\n",
      "looking look VERB VBG ROOT xxxx True False\n",
      "at at ADP IN prep xx True True\n",
      "buying buy VERB VBG pcomp xxxx True False\n",
      "U.K. U.K. PROPN NNP nsubj X.X. False False\n",
      "startup startup VERB VBD ccomp xxxx True False\n",
      "for for ADP IN prep xxx True True\n",
      "$ $ SYM $ quantmod $ False False\n",
      "1 1 NUM CD compound d False False\n",
      "billion billion NUM CD pobj xxxx True False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_,token.tag_, token.dep_,\n",
    "          token.shape_, token.is_alpha, token.is_stop)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25b7e97",
   "metadata": {},
   "source": [
    "# Text Summariziation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47792ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"There are broadly two types of extractive summarization tasks depending on what the summarization program\n",
    "focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the \n",
    "collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant \n",
    "summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization\n",
    "systems are able to create both query relevant text summaries and generic machine-generated summaries depending on \n",
    "what the user needs.\n",
    "\n",
    "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract \n",
    "from a given document. Sometimes one might be interested in generating a summary from a single source document, while\n",
    "others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is \n",
    "called multi-document summarization. A related application is summarizing news articles. Imagine a system, which \n",
    "automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news \n",
    "as a summary.\n",
    "\n",
    "Image collection summarization is another application example of automatic summarization. It consists in selecting a \n",
    "representative set of images from a larger set of images.[4] A summary in this context is useful to show the most \n",
    "representative images of results in an image collection exploration system. Video summarization is a related domain, \n",
    "where the system automatically creates a trailer of a long video. This also has applications in consumer or personal\n",
    "videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would\n",
    "want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are broadly two types of extractive summarization tasks depending on what the summarization program\\nfocuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the \\ncollection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant \\nsummarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization\\nsystems are able to create both query relevant text summaries and generic machine-generated summaries depending on \\nwhat the user needs.\\n\\nAn example of a summarization problem is document summarization, which attempts to automatically produce an abstract \\nfrom a given document. Sometimes one might be interested in generating a summary from a single source document, while\\nothers can use multiple source documents (for example, a cluster of articles on the same topic). This problem is \\ncalled multi-document summarization. A related application is summarizing news articles. Imagine a system, which \\nautomatically pulls together news articles on a given topic (from the web), and concisely represents the latest news \\nas a summary.\\n\\nImage collection summarization is another application example of automatic summarization. It consists in selecting a \\nrepresentative set of images from a larger set of images.[4] A summary in this context is useful to show the most \\nrepresentative images of results in an image collection exploration system. Video summarization is a related domain, \\nwhere the system automatically creates a trailer of a long video. This also has applications in consumer or personal\\nvideos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would\\nwant to extract important and suspicious activity, while ignoring all the boring and redundant frames captured '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f8e3c",
   "metadata": {},
   "source": [
    "# steps\n",
    "\n",
    "# 1 document - Tokens\n",
    "# 2 Tokens score - Token Frequency\n",
    "# 3 weighted Tokens Frequency\n",
    "# 4 document sentence\n",
    "# 5 Sentence == Collection Score\n",
    "# 6 Tokens Score = Sentence Score\n",
    "# 7 Score Ascending -- Top Sentence scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e55a4490",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d647705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['though',\n",
       " 'yours',\n",
       " 'more',\n",
       " '’m',\n",
       " 'there',\n",
       " 'full',\n",
       " 'someone',\n",
       " 'her',\n",
       " 'most',\n",
       " 'except',\n",
       " '’d',\n",
       " 'also',\n",
       " 'each',\n",
       " 'beside',\n",
       " 'several',\n",
       " 'only',\n",
       " 'wherever',\n",
       " 'go',\n",
       " 'down',\n",
       " 'even',\n",
       " 'the',\n",
       " 'whatever',\n",
       " 'amount',\n",
       " 'toward',\n",
       " 'were',\n",
       " 'otherwise',\n",
       " 'yet',\n",
       " 'around',\n",
       " 'eleven',\n",
       " 'see',\n",
       " 'together',\n",
       " '‘ve',\n",
       " 'after',\n",
       " 'do',\n",
       " 'of',\n",
       " 'quite',\n",
       " 'already',\n",
       " 'besides',\n",
       " 'further',\n",
       " 'never',\n",
       " 'whither',\n",
       " 'those',\n",
       " 'will',\n",
       " 'hereafter',\n",
       " 'we',\n",
       " 'for',\n",
       " 'anyway',\n",
       " \"'m\",\n",
       " 'becomes',\n",
       " 'five',\n",
       " '‘re',\n",
       " 'keep',\n",
       " 'its',\n",
       " 'our',\n",
       " 'thereafter',\n",
       " 'whereafter',\n",
       " 'alone',\n",
       " 'third',\n",
       " 'himself',\n",
       " 'into',\n",
       " 'beyond',\n",
       " 'anywhere',\n",
       " 'four',\n",
       " 'while',\n",
       " 'with',\n",
       " 'below',\n",
       " 'myself',\n",
       " 'sometimes',\n",
       " 'enough',\n",
       " 'last',\n",
       " 'therein',\n",
       " 'themselves',\n",
       " 'your',\n",
       " 'almost',\n",
       " 'else',\n",
       " 'without',\n",
       " 'nine',\n",
       " 'above',\n",
       " 'ever',\n",
       " 'what',\n",
       " 'nevertheless',\n",
       " 'throughout',\n",
       " 'all',\n",
       " '’ll',\n",
       " 'although',\n",
       " 'whenever',\n",
       " 'neither',\n",
       " 'twelve',\n",
       " 'seems',\n",
       " 'using',\n",
       " 'as',\n",
       " 'rather',\n",
       " 'are',\n",
       " 'bottom',\n",
       " 'am',\n",
       " 'such',\n",
       " 'meanwhile',\n",
       " 'either',\n",
       " 'somewhere',\n",
       " 'everything',\n",
       " 'therefore',\n",
       " 'say',\n",
       " 'through',\n",
       " 'call',\n",
       " 'have',\n",
       " '’ve',\n",
       " 'take',\n",
       " 'due',\n",
       " 'become',\n",
       " 'nobody',\n",
       " 'top',\n",
       " 'other',\n",
       " 'their',\n",
       " 'can',\n",
       " 'ca',\n",
       " 'however',\n",
       " 'six',\n",
       " 'first',\n",
       " 'whether',\n",
       " 'at',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'whoever',\n",
       " 'amongst',\n",
       " 'in',\n",
       " 'may',\n",
       " 'whereby',\n",
       " 'becoming',\n",
       " 'yourselves',\n",
       " 'until',\n",
       " 'being',\n",
       " 'fifteen',\n",
       " 'whereupon',\n",
       " 'within',\n",
       " 'make',\n",
       " 'a',\n",
       " 'eight',\n",
       " 'thereby',\n",
       " 'doing',\n",
       " 'whose',\n",
       " 'moreover',\n",
       " 'could',\n",
       " 'afterwards',\n",
       " 'he',\n",
       " 'sixty',\n",
       " 'beforehand',\n",
       " 'under',\n",
       " 'thereupon',\n",
       " 'which',\n",
       " 'upon',\n",
       " '‘s',\n",
       " 'some',\n",
       " 'had',\n",
       " 'front',\n",
       " 'about',\n",
       " 'how',\n",
       " 'thence',\n",
       " 'against',\n",
       " 'every',\n",
       " 'among',\n",
       " 'perhaps',\n",
       " 'thru',\n",
       " 'does',\n",
       " 'really',\n",
       " 'no',\n",
       " 'been',\n",
       " \"'re\",\n",
       " 'was',\n",
       " 'n’t',\n",
       " 'then',\n",
       " 'ourselves',\n",
       " 'forty',\n",
       " 'off',\n",
       " 'via',\n",
       " 'somehow',\n",
       " '‘m',\n",
       " 'herein',\n",
       " '’re',\n",
       " 'anyone',\n",
       " 'or',\n",
       " 'out',\n",
       " \"n't\",\n",
       " 'before',\n",
       " 'made',\n",
       " 'between',\n",
       " 'two',\n",
       " 'where',\n",
       " 'whereas',\n",
       " 'seemed',\n",
       " '‘d',\n",
       " 'yourself',\n",
       " 'seeming',\n",
       " 'hereby',\n",
       " 'fifty',\n",
       " 'serious',\n",
       " 'move',\n",
       " 'unless',\n",
       " 'well',\n",
       " 'us',\n",
       " 'part',\n",
       " 'own',\n",
       " 'during',\n",
       " 'would',\n",
       " 'along',\n",
       " 'an',\n",
       " 'per',\n",
       " 'nothing',\n",
       " 'who',\n",
       " 'cannot',\n",
       " 'often',\n",
       " 'always',\n",
       " 'next',\n",
       " 'has',\n",
       " 'she',\n",
       " 'me',\n",
       " 'back',\n",
       " 'many',\n",
       " 'various',\n",
       " 'same',\n",
       " 'but',\n",
       " 'them',\n",
       " 'twenty',\n",
       " 'anything',\n",
       " 'him',\n",
       " 'too',\n",
       " 'show',\n",
       " 'both',\n",
       " 'mine',\n",
       " 'once',\n",
       " 'towards',\n",
       " 'to',\n",
       " 'and',\n",
       " 'give',\n",
       " 'if',\n",
       " 'my',\n",
       " 'ten',\n",
       " 'it',\n",
       " 'please',\n",
       " 'whom',\n",
       " 'should',\n",
       " 'across',\n",
       " 'empty',\n",
       " \"'d\",\n",
       " 'much',\n",
       " 'still',\n",
       " 'wherein',\n",
       " 're',\n",
       " 'thus',\n",
       " 'nowhere',\n",
       " 'on',\n",
       " 'very',\n",
       " 'others',\n",
       " 'elsewhere',\n",
       " 'another',\n",
       " 'this',\n",
       " 'now',\n",
       " 'over',\n",
       " 'former',\n",
       " '’s',\n",
       " 'ours',\n",
       " 'seem',\n",
       " 'hereupon',\n",
       " 'namely',\n",
       " 'latter',\n",
       " 'here',\n",
       " 'indeed',\n",
       " 'hers',\n",
       " 'whole',\n",
       " 'these',\n",
       " 'be',\n",
       " 'sometime',\n",
       " '‘ll',\n",
       " 'any',\n",
       " 'by',\n",
       " 'mostly',\n",
       " 'because',\n",
       " 'up',\n",
       " 'name',\n",
       " 'became',\n",
       " 'that',\n",
       " 'when',\n",
       " 'since',\n",
       " 'so',\n",
       " 'put',\n",
       " 'latterly',\n",
       " 'his',\n",
       " 'onto',\n",
       " \"'s\",\n",
       " 'something',\n",
       " 'behind',\n",
       " 'side',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'get',\n",
       " \"'ve\",\n",
       " \"'ll\",\n",
       " 'noone',\n",
       " 'regarding',\n",
       " 'none',\n",
       " 'herself',\n",
       " 'why',\n",
       " 'did',\n",
       " 'must',\n",
       " 'everywhere',\n",
       " 'least',\n",
       " 'less',\n",
       " 'from',\n",
       " 'n‘t',\n",
       " 'they',\n",
       " 'everyone',\n",
       " 'formerly',\n",
       " 'again',\n",
       " 'three',\n",
       " 'hence',\n",
       " 'might',\n",
       " 'few',\n",
       " 'done',\n",
       " 'anyhow',\n",
       " 'is',\n",
       " 'i',\n",
       " 'hundred',\n",
       " 'whence',\n",
       " 'one',\n",
       " 'you',\n",
       " 'used',\n",
       " 'than']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = list(STOP_WORDS)\n",
    "stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d680133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are broadly two types of extractive summarization tasks depending on what the summarization program\\nfocuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the \\ncollection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant \\nsummarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization\\nsystems are able to create both query relevant text summaries and generic machine-generated summaries depending on \\nwhat the user needs.\\n\\nAn example of a summarization problem is document summarization, which attempts to automatically produce an abstract \\nfrom a given document. Sometimes one might be interested in generating a summary from a single source document, while\\nothers can use multiple source documents (for example, a cluster of articles on the same topic). This problem is \\ncalled multi-document summarization. A related application is summarizing news articles. Imagine a system, which \\nautomatically pulls together news articles on a given topic (from the web), and concisely represents the latest news \\nas a summary.\\n\\nImage collection summarization is another application example of automatic summarization. It consists in selecting a \\nrepresentative set of images from a larger set of images.[4] A summary in this context is useful to show the most \\nrepresentative images of results in an image collection exploration system. Video summarization is a related domain, \\nwhere the system automatically creates a trailer of a long video. This also has applications in consumer or personal\\nvideos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would\\nwant to extract important and suspicious activity, while ignoring all the boring and redundant frames captured '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "There are broadly two types of extractive summarization tasks depending on what the summarization program\n",
       "focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the \n",
       "collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant \n",
       "summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization\n",
       "systems are able to create both query relevant text summaries and generic machine-generated summaries depending on \n",
       "what the user needs.\n",
       "\n",
       "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract \n",
       "from a given document. Sometimes one might be interested in generating a summary from a single source document, while\n",
       "others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is \n",
       "called multi-document summarization. A related application is summarizing news articles. Imagine a system, which \n",
       "automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news \n",
       "as a summary.\n",
       "\n",
       "Image collection summarization is another application example of automatic summarization. It consists in selecting a \n",
       "representative set of images from a larger set of images.[4] A summary in this context is useful to show the most \n",
       "representative images of results in an image collection exploration system. Video summarization is a related domain, \n",
       "where the system automatically creates a trailer of a long video. This also has applications in consumer or personal\n",
       "videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would\n",
       "want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Doc = nlp(text) \n",
    "Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There', 'are', 'broadly', 'two', 'types', 'of', 'extractive', 'summarization', 'tasks', 'depending', 'on', 'what', 'the', 'summarization', 'program', '\\n', 'focuses', 'on', '.', 'The', 'first', 'is', 'generic', 'summarization', ',', 'which', 'focuses', 'on', 'obtaining', 'a', 'generic', 'summary', 'or', 'abstract', 'of', 'the', '\\n', 'collection', '(', 'whether', 'documents', ',', 'or', 'sets', 'of', 'images', ',', 'or', 'videos', ',', 'news', 'stories', 'etc', '.', ')', '.', 'The', 'second', 'is', 'query', 'relevant', '\\n', 'summarization', ',', 'sometimes', 'called', 'query', '-', 'based', 'summarization', ',', 'which', 'summarizes', 'objects', 'specific', 'to', 'a', 'query', '.', 'Summarization', '\\n', 'systems', 'are', 'able', 'to', 'create', 'both', 'query', 'relevant', 'text', 'summaries', 'and', 'generic', 'machine', '-', 'generated', 'summaries', 'depending', 'on', '\\n', 'what', 'the', 'user', 'needs', '.', '\\n\\n', 'An', 'example', 'of', 'a', 'summarization', 'problem', 'is', 'document', 'summarization', ',', 'which', 'attempts', 'to', 'automatically', 'produce', 'an', 'abstract', '\\n', 'from', 'a', 'given', 'document', '.', 'Sometimes', 'one', 'might', 'be', 'interested', 'in', 'generating', 'a', 'summary', 'from', 'a', 'single', 'source', 'document', ',', 'while', '\\n', 'others', 'can', 'use', 'multiple', 'source', 'documents', '(', 'for', 'example', ',', 'a', 'cluster', 'of', 'articles', 'on', 'the', 'same', 'topic', ')', '.', 'This', 'problem', 'is', '\\n', 'called', 'multi', '-', 'document', 'summarization', '.', 'A', 'related', 'application', 'is', 'summarizing', 'news', 'articles', '.', 'Imagine', 'a', 'system', ',', 'which', '\\n', 'automatically', 'pulls', 'together', 'news', 'articles', 'on', 'a', 'given', 'topic', '(', 'from', 'the', 'web', ')', ',', 'and', 'concisely', 'represents', 'the', 'latest', 'news', '\\n', 'as', 'a', 'summary', '.', '\\n\\n', 'Image', 'collection', 'summarization', 'is', 'another', 'application', 'example', 'of', 'automatic', 'summarization', '.', 'It', 'consists', 'in', 'selecting', 'a', '\\n', 'representative', 'set', 'of', 'images', 'from', 'a', 'larger', 'set', 'of', 'images.[4', ']', 'A', 'summary', 'in', 'this', 'context', 'is', 'useful', 'to', 'show', 'the', 'most', '\\n', 'representative', 'images', 'of', 'results', 'in', 'an', 'image', 'collection', 'exploration', 'system', '.', 'Video', 'summarization', 'is', 'a', 'related', 'domain', ',', '\\n', 'where', 'the', 'system', 'automatically', 'creates', 'a', 'trailer', 'of', 'a', 'long', 'video', '.', 'This', 'also', 'has', 'applications', 'in', 'consumer', 'or', 'personal', '\\n', 'videos', ',', 'where', 'one', 'might', 'want', 'to', 'skip', 'the', 'boring', 'or', 'repetitive', 'actions', '.', 'Similarly', ',', 'in', 'surveillance', 'videos', ',', 'one', 'would', '\\n', 'want', 'to', 'extract', 'important', 'and', 'suspicious', 'activity', ',', 'while', 'ignoring', 'all', 'the', 'boring', 'and', 'redundant', 'frames', 'captured']\n"
     ]
    }
   ],
   "source": [
    "# lets get the tokens from text\n",
    "tokens = [token.text for token in Doc]\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "There are broadly two types of extractive summarization tasks depending on what the summarization program\n",
       "focuses on. The first is generic summarization, which focuses on obtaining a generic summary or abstract of the \n",
       "collection (whether documents, or sets of images, or videos, news stories etc.). The second is query relevant \n",
       "summarization, sometimes called query-based summarization, which summarizes objects specific to a query. Summarization\n",
       "systems are able to create both query relevant text summaries and generic machine-generated summaries depending on \n",
       "what the user needs.\n",
       "\n",
       "An example of a summarization problem is document summarization, which attempts to automatically produce an abstract \n",
       "from a given document. Sometimes one might be interested in generating a summary from a single source document, while\n",
       "others can use multiple source documents (for example, a cluster of articles on the same topic). This problem is \n",
       "called multi-document summarization. A related application is summarizing news articles. Imagine a system, which \n",
       "automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news \n",
       "as a summary.\n",
       "\n",
       "Image collection summarization is another application example of automatic summarization. It consists in selecting a \n",
       "representative set of images from a larger set of images.[4] A summary in this context is useful to show the most \n",
       "representative images of results in an image collection exploration system. Video summarization is a related domain, \n",
       "where the system automatically creates a trailer of a long video. This also has applications in consumer or personal\n",
       "videos, where one might want to skip the boring or repetitive actions. Similarly, in surveillance videos, one would\n",
       "want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the frequency of each word tokens, how many times tokens is repeated in the text\n",
    "\n",
    "word_frequencies = {}\n",
    "\n",
    "for word in Doc:\n",
    "    if word.text.lower() not in stopwords:\n",
    "        if word.text.lower() not in punctuation:\n",
    "            if word.text not in word_frequencies.keys():\n",
    "                word_frequencies[word.text] = 1\n",
    "            else:\n",
    "                word_frequencies[word.text] += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'broadly': 1,\n",
       " 'types': 1,\n",
       " 'extractive': 1,\n",
       " 'summarization': 5,\n",
       " 'tasks': 1,\n",
       " 'depending': 1,\n",
       " 'program': 1,\n",
       " '\\n': 3,\n",
       " 'focuses': 2,\n",
       " 'generic': 2,\n",
       " 'obtaining': 1,\n",
       " 'summary': 1,\n",
       " 'abstract': 1,\n",
       " 'collection': 1,\n",
       " 'documents': 1,\n",
       " 'sets': 1,\n",
       " 'images': 1,\n",
       " 'videos': 1,\n",
       " 'news': 1,\n",
       " 'stories': 1,\n",
       " 'etc': 1,\n",
       " 'second': 1,\n",
       " 'query': 3,\n",
       " 'relevant': 1,\n",
       " 'called': 1,\n",
       " 'based': 1,\n",
       " 'summarizes': 1,\n",
       " 'objects': 1,\n",
       " 'specific': 1}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_frequency = max(word_frequencies.values())\n",
    "max_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2931397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get the normalized / weighted frequency you should all frequencies by the maximum frequency(15)\n",
    "\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = (word_frequencies[word]/max_frequency) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'broadly': 0.06666666666666667,\n",
       " 'types': 0.06666666666666667,\n",
       " 'extractive': 0.06666666666666667,\n",
       " 'summarization': 0.7333333333333333,\n",
       " 'tasks': 0.06666666666666667,\n",
       " 'depending': 0.13333333333333333,\n",
       " 'program': 0.06666666666666667,\n",
       " '\\n': 1.0,\n",
       " 'focuses': 0.13333333333333333,\n",
       " 'generic': 0.2,\n",
       " 'obtaining': 0.06666666666666667,\n",
       " 'summary': 0.26666666666666666,\n",
       " 'abstract': 0.13333333333333333,\n",
       " 'collection': 0.2,\n",
       " 'documents': 0.13333333333333333,\n",
       " 'sets': 0.06666666666666667,\n",
       " 'images': 0.2,\n",
       " 'videos': 0.2,\n",
       " 'news': 0.26666666666666666,\n",
       " 'stories': 0.06666666666666667,\n",
       " 'etc': 0.06666666666666667,\n",
       " 'second': 0.06666666666666667,\n",
       " 'query': 0.26666666666666666,\n",
       " 'relevant': 0.13333333333333333,\n",
       " 'called': 0.13333333333333333,\n",
       " 'based': 0.06666666666666667,\n",
       " 'summarizes': 0.06666666666666667,\n",
       " 'objects': 0.06666666666666667,\n",
       " 'specific': 0.06666666666666667,\n",
       " 'Summarization': 0.06666666666666667,\n",
       " 'systems': 0.06666666666666667,\n",
       " 'able': 0.06666666666666667,\n",
       " 'create': 0.06666666666666667,\n",
       " 'text': 0.06666666666666667,\n",
       " 'summaries': 0.13333333333333333,\n",
       " 'machine': 0.06666666666666667,\n",
       " 'generated': 0.06666666666666667,\n",
       " 'user': 0.06666666666666667,\n",
       " 'needs': 0.06666666666666667,\n",
       " '\\n\\n': 0.13333333333333333,\n",
       " 'example': 0.2,\n",
       " 'problem': 0.13333333333333333,\n",
       " 'document': 0.26666666666666666,\n",
       " 'attempts': 0.06666666666666667,\n",
       " 'automatically': 0.2,\n",
       " 'produce': 0.06666666666666667,\n",
       " 'given': 0.13333333333333333,\n",
       " 'interested': 0.06666666666666667,\n",
       " 'generating': 0.06666666666666667,\n",
       " 'single': 0.06666666666666667,\n",
       " 'source': 0.13333333333333333,\n",
       " 'use': 0.06666666666666667,\n",
       " 'multiple': 0.06666666666666667,\n",
       " 'cluster': 0.06666666666666667,\n",
       " 'articles': 0.2,\n",
       " 'topic': 0.13333333333333333,\n",
       " 'multi': 0.06666666666666667,\n",
       " 'related': 0.13333333333333333,\n",
       " 'application': 0.13333333333333333,\n",
       " 'summarizing': 0.06666666666666667,\n",
       " 'Imagine': 0.06666666666666667,\n",
       " 'system': 0.2,\n",
       " 'pulls': 0.06666666666666667,\n",
       " 'web': 0.06666666666666667,\n",
       " 'concisely': 0.06666666666666667,\n",
       " 'represents': 0.06666666666666667,\n",
       " 'latest': 0.06666666666666667,\n",
       " 'Image': 0.06666666666666667,\n",
       " 'automatic': 0.06666666666666667,\n",
       " 'consists': 0.06666666666666667,\n",
       " 'selecting': 0.06666666666666667,\n",
       " 'representative': 0.13333333333333333,\n",
       " 'set': 0.13333333333333333,\n",
       " 'larger': 0.06666666666666667,\n",
       " 'images.[4': 0.06666666666666667,\n",
       " 'context': 0.06666666666666667,\n",
       " 'useful': 0.06666666666666667,\n",
       " 'results': 0.06666666666666667,\n",
       " 'image': 0.06666666666666667,\n",
       " 'exploration': 0.06666666666666667,\n",
       " 'Video': 0.06666666666666667,\n",
       " 'domain': 0.06666666666666667,\n",
       " 'creates': 0.06666666666666667,\n",
       " 'trailer': 0.06666666666666667,\n",
       " 'long': 0.06666666666666667,\n",
       " 'video': 0.06666666666666667,\n",
       " 'applications': 0.06666666666666667,\n",
       " 'consumer': 0.06666666666666667,\n",
       " 'personal': 0.06666666666666667,\n",
       " 'want': 0.13333333333333333,\n",
       " 'skip': 0.06666666666666667,\n",
       " 'boring': 0.13333333333333333,\n",
       " 'repetitive': 0.06666666666666667,\n",
       " 'actions': 0.06666666666666667,\n",
       " 'Similarly': 0.06666666666666667,\n",
       " 'surveillance': 0.06666666666666667,\n",
       " 'extract': 0.06666666666666667,\n",
       " 'important': 0.06666666666666667,\n",
       " 'suspicious': 0.06666666666666667,\n",
       " 'activity': 0.06666666666666667,\n",
       " 'ignoring': 0.06666666666666667,\n",
       " 'redundant': 0.06666666666666667,\n",
       " 'frames': 0.06666666666666667,\n",
       " 'captured': 0.06666666666666667}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[There are broadly two types of extractive summarization tasks depending on what the summarization program\n",
       " focuses on.,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the \n",
       " collection (whether documents, or sets of images, or videos, news stories etc.).,\n",
       " The second is query relevant \n",
       " summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n",
       " Summarization\n",
       " systems are able to create both query relevant text summaries and generic machine-generated summaries depending on \n",
       " what the user needs.\n",
       " ,\n",
       " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract \n",
       " from a given document.,\n",
       " Sometimes one might be interested in generating a summary from a single source document, while\n",
       " others can use multiple source documents (for example, a cluster of articles on the same topic).,\n",
       " This problem is \n",
       " called multi-document summarization.,\n",
       " A related application is summarizing news articles.,\n",
       " Imagine a system, which \n",
       " automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news \n",
       " as a summary.\n",
       " ,\n",
       " Image collection summarization is another application example of automatic summarization.,\n",
       " It consists in selecting a \n",
       " representative set of images from a larger set of images.[4],\n",
       " A summary in this context is useful to show the most \n",
       " representative images of results in an image collection exploration system.,\n",
       " Video summarization is a related domain, \n",
       " where the system automatically creates a trailer of a long video.,\n",
       " This also has applications in consumer or personal\n",
       " videos, where one might want to skip the boring or repetitive actions.,\n",
       " Similarly, in surveillance videos, one would\n",
       " want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_tokens = [sent for sent in Doc.sents]\n",
    "sentences_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[There are broadly two types of extractive summarization tasks depending on what the summarization program\n",
       " focuses on.,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the \n",
       " collection (whether documents, or sets of images, or videos, news stories etc.).,\n",
       " The second is query relevant \n",
       " summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n",
       " Summarization\n",
       " systems are able to create both query relevant text summaries and generic machine-generated summaries depending on \n",
       " what the user needs.\n",
       " ,\n",
       " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract \n",
       " from a given document.,\n",
       " Sometimes one might be interested in generating a summary from a single source document, while\n",
       " others can use multiple source documents (for example, a cluster of articles on the same topic).,\n",
       " This problem is \n",
       " called multi-document summarization.,\n",
       " A related application is summarizing news articles.,\n",
       " Imagine a system, which \n",
       " automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news \n",
       " as a summary.\n",
       " ,\n",
       " Image collection summarization is another application example of automatic summarization.,\n",
       " It consists in selecting a \n",
       " representative set of images from a larger set of images.[4],\n",
       " A summary in this context is useful to show the most \n",
       " representative images of results in an image collection exploration system.,\n",
       " Video summarization is a related domain, \n",
       " where the system automatically creates a trailer of a long video.,\n",
       " This also has applications in consumer or personal\n",
       " videos, where one might want to skip the boring or repetitive actions.,\n",
       " Similarly, in surveillance videos, one would\n",
       " want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d3f5059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the sentence score , to calculate the sentence score\n",
    "#  the sentence score we need to add the word frequency of each word in the sentence\n",
    "sentence_scores = {}\n",
    "\n",
    "for sent in sentences_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in word_frequencies.keys():\n",
    "            if sent not in sentence_scores.keys():\n",
    "                sentence_scores[sent] = word_frequencies[word.text.lower()]\n",
    "            else:\n",
    "                sentence_scores[sent] += word_frequencies[word.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{There are broadly two types of extractive summarization tasks depending on what the summarization program\n",
       " focuses on.: 3.066666666666667,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the \n",
       " collection (whether documents, or sets of images, or videos, news stories etc.).: 3.9333333333333345,\n",
       " The second is query relevant \n",
       " summarization, sometimes called query-based summarization, which summarizes objects specific to a query.: 3.8666666666666676,\n",
       " Summarization\n",
       " systems are able to create both query relevant text summaries and generic machine-generated summaries depending on \n",
       " what the user needs.\n",
       " : 4.400000000000001,\n",
       " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract \n",
       " from a given document.: 3.9333333333333336,\n",
       " Sometimes one might be interested in generating a summary from a single source document, while\n",
       " others can use multiple source documents (for example, a cluster of articles on the same topic).: 2.866666666666667,\n",
       " This problem is \n",
       " called multi-document summarization.: 2.333333333333333,\n",
       " A related application is summarizing news articles.: 0.8,\n",
       " Imagine a system, which \n",
       " automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news \n",
       " as a summary.\n",
       " : 4.133333333333335,\n",
       " Image collection summarization is another application example of automatic summarization.: 2.1333333333333333,\n",
       " It consists in selecting a \n",
       " representative set of images from a larger set of images.[4]: 1.8666666666666665,\n",
       " A summary in this context is useful to show the most \n",
       " representative images of results in an image collection exploration system.: 2.3333333333333335,\n",
       " Video summarization is a related domain, \n",
       " where the system automatically creates a trailer of a long video.: 2.666666666666668,\n",
       " This also has applications in consumer or personal\n",
       " videos, where one might want to skip the boring or repetitive actions.: 1.8666666666666665,\n",
       " Similarly, in surveillance videos, one would\n",
       " want to extract important and suspicious activity, while ignoring all the boring and redundant frames captured: 2.0666666666666664}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d83eac5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let say our case study was 30% sentence  with highest score\n",
    "from heapq import nlargest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75784b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select_len = int(len(sentences_tokens)*0.3)\n",
    "#select_len\n",
    "\n",
    "\n",
    "select_len = int(len(sentences_tokens)*0.4)\n",
    "select_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d7335434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have to select maximum 40% sentences from the sentence scores\n",
    "\n",
    "summary = nlargest(select_len, sentence_scores, key=sentence_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7b95aca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Summarization\n",
       " systems are able to create both query relevant text summaries and generic machine-generated summaries depending on \n",
       " what the user needs.\n",
       " ,\n",
       " Imagine a system, which \n",
       " automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news \n",
       " as a summary.\n",
       " ,\n",
       " The first is generic summarization, which focuses on obtaining a generic summary or abstract of the \n",
       " collection (whether documents, or sets of images, or videos, news stories etc.).,\n",
       " An example of a summarization problem is document summarization, which attempts to automatically produce an abstract \n",
       " from a given document.,\n",
       " The second is query relevant \n",
       " summarization, sometimes called query-based summarization, which summarizes objects specific to a query.,\n",
       " There are broadly two types of extractive summarization tasks depending on what the summarization program\n",
       " focuses on.]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if i need  to combine these top 3 sentences then\n",
    "\n",
    "final_summary = [word.text for word in summary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Summarization\\nsystems are able to create both query relevant text summaries and generic machine-generated summaries depending on \\nwhat the user needs.\\n\\n',\n",
       " 'Imagine a system, which \\nautomatically pulls together news articles on a given topic (from the web), and concisely represents the latest news \\nas a summary.\\n\\n',\n",
       " 'The first is generic summarization, which focuses on obtaining a generic summary or abstract of the \\ncollection (whether documents, or sets of images, or videos, news stories etc.).',\n",
       " 'An example of a summarization problem is document summarization, which attempts to automatically produce an abstract \\nfrom a given document.',\n",
       " 'The second is query relevant \\nsummarization, sometimes called query-based summarization, which summarizes objects specific to a query.',\n",
       " 'There are broadly two types of extractive summarization tasks depending on what the summarization program\\nfocuses on.']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a4a9d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Summarization\n",
      "systems are able to create both query relevant text summaries and generic machine-generated summaries depending on \n",
      "what the user needs.\n",
      "\n",
      ", Imagine a system, which \n",
      "automatically pulls together news articles on a given topic (from the web), and concisely represents the latest news \n",
      "as a summary.\n",
      "\n",
      ", The first is generic summarization, which focuses on obtaining a generic summary or abstract of the \n",
      "collection (whether documents, or sets of images, or videos, news stories etc.)., An example of a summarization problem is document summarization, which attempts to automatically produce an abstract \n",
      "from a given document., The second is query relevant \n",
      "summarization, sometimes called query-based summarization, which summarizes objects specific to a query., There are broadly two types of extractive summarization tasks depending on what the summarization program\n",
      "focuses on.]\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
